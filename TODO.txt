We should gracefully retry on one of these:
Requesting (1): "http://jacksonville.craigslist.org/for/2161001710.html"
/usr/lib/ruby/1.8/net/http.rb:2022:in `read_status_line': wrong status line: "HTTP/1.1  " (Net::HTTPBadResponse)
       from /usr/lib/ruby/1.8/net/http.rb:2009:in `read_new'
       from /usr/lib/ruby/1.8/net/http.rb:1050:in `request'
       from /usr/lib/ruby/1.8/net/http.rb:1037:in `request'
       from /usr/lib/ruby/1.8/net/http.rb:543:in `start'
       from /usr/lib/ruby/1.8/net/http.rb:1035:in `request'
       from /usr/lib/ruby/1.8/net/http.rb:772:in `get'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/scraper.rb:156:in `fetch_http'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/scraper.rb:144:in `fetch_uri'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/scraper.rb:166:in `fetch_http'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/scraper.rb:144:in `fetch_uri'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/scraper.rb:201:in `html_source'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/posting.rb:114:in `contents'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/posting.rb:290:in `system_post?'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:278:in `passes_filter?'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:500
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:487:in `each'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:487
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:485:in `catch'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:485
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/libcraigscrape.rb:55:in `each_listing'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/libcraigscrape.rb:55:in `each'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/lib/libcraigscrape.rb:55:in `each_listing'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:463
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:450:in `collect'
       from /usr/lib/ruby/gems/1.8/gems/libcraigscrape-0.9.1/bin/craigwatch:450
       from /usr/bin/craigwatch:19:in `load'
       from /usr/bin/craigwatch:19
------------------------------------------
* There's a bug where the rdoc generates Crauigscrape weird in the package. It has to do with this not being the case in the gem:
	  * # NOTE: If you don't put libcraigscrape.rb at the beginning, the rdoc ends up looking a little screwy
      rdoc.rdoc_files.add RDOC_FILES+Dir.glob('lib/*.rb').sort_by{|a,b| (a == 'lib/libcraigscrape.rb') ? -1 : 0 } 
		* In fact, we might want to move all those requires up to the top of libcraigscrape again  once we fix this... 

* Add craigwatch filter object tests....

------------------------------------------
Possible features?:
 * FEATURE: Rather then 'search/sss?query=artist+needed', maybe use CraigScrape::search_for('artist needed')
 * FEATURE: Support for post submissions?
 * FEATURE: Add the craigwatch_debug feature - and monitor it... (There's a TODO in there...)
	* Shows the current progress...? (pages fetched, objects in caches..) 
 * FEATURE: Get the YAML template features working in the chris_report.yml
 	* should be pretty easy - I think we just add to the schema
 	* Might have to do this yourself with a search_templates section and an search ':include' thing
   * Should we have 'defined searches' in the yaml and then apply these defitions to a report? 
 		* It would be nice to have one search definition for 'art I want' and then allow these
	 	* to be referenced in separate reports for 'art in florida', 'art in nyc', 'art everywhere esle' ..
	 	* The other  thing I'd like to do though is have "New art watch/Classic Artwatch" type reports that look
	 	* separate - but that dont cause the crawl to happen twice. Just once with two reports per crawl..
 * FEATURE: Page-caching? Maybe? Any interest? might be nice for geocaching...
 * FEATURE: Stats in the email: bytes transferred, generation time, urls scrapped, posts scrapped
 
 * FEATURE: We might want to parse the sub-locations in the geo-location code... (so for miami: brw/mia/wpb)

------------------------------------------
# Quickie craigscrape examples/tests:
$: << './lib'
require 'libcraigscrape'

CraigScrape.new('us/fl/miami', 'us/fl/keys').posts_since(Time.now - 3600*48, 'search/sss?query=z06')
CraigScrape.new('us/fl/miami').posts('search/sss?query=z06')
i=0; CraigScrape.new('us/fl/miami', 'us/fl/keys').each_post('rea', 'search/sss?query=rack'){|p| break if i>50; puts p.inspect ;i += 1;}
CraigScrape.new('us/fl/miami', 'us/fl/keys').each_listing('rea', 'search/sss?query=rack'){ |listing| puts listing.inspect }
CraigScrape.new('us/fl/miami', 'us/fl/keys').listings('rea', 'search/sss?query=rack')


-----------------------------------------
# Quickie way to analyze an email:
$: << './lib'
require 'libcraigscrape'

email=<<EOD
email contents here
EOD
r=/regex-here/

email.tr('\n', '').scan( /http\:\/\/[^ \"]+/).reject{|l| !/\.html/.match l}.each{ |l|
  puts "\nURL: %s" % l
  c = CraigScrape::Posting.new l
  puts "  * Label : %s" % r.match(c.label).to_a[0]
  puts "  * Contents: %s" % r.match(c.contents_as_plain).to_a[0]
}

-----------------------------------------
