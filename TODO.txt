* Fix that annoying fucking 404 bug in the craigwatch where it wont stop!
* Go through the rdoc README and otherwise todos - 
 	* adjust the scrape_ reference(s) to use the CraigScrape.new(*paths) syntax
   * Add a listings: [ brw/apa ] example in both the api and the examples (notice the brw)
   * Make a note about how to think ahead so your memory consumption doesnt get ridiculous


* Test the last of the examples, and publish!
	* TEST: Scrape Single Craigslist Posting
	* TEST: Scrape Single Craigslist Listing

Post-0.8.0:
	* Ruby 1.9 support
	
Post-0.8.1:
 * FEATURE: Rather then 'search/sss?query=artist+needed', maybe use CraigScrape::search_for('artist needed')
 * FEATURE: Add the craigwatch_debug feature - and monitor it... (There's a TODO in there...)
	* Shows the current progress...? (pages fetched, objects in caches..) 
 * FEATURE: Get the YAML template features working in the chris_report.yml
 	* should be pretty easy - I think we just add to the schema
 	* Might have to do this yourself with a search_templates section and an search ':include' thing
   * Should we have 'defined searches' in the yaml and then apply these defitions to a report? 
 		* It would be nice to have one search definition for 'art I want' and then allow these
	 	* to be referenced in separate reports for 'art in florida', 'art in nyc', 'art everywhere esle' ..
	 	* The other  thing I'd like to do though is have "New art watch/Classic Artwatch" type reports that look
	 	* separate - but that dont cause the crawl to happen twice. Just once with two reports per crawl..
 * FEATURE: Page-caching? Maybe? Any interest? would be nice particularly for geocaching...
 * FEATURE: Stats in the email: bytes transferred, generation time, urls scrapped, posts scrapped
 
 * FEATURE: We might want to parse the sub-locations in the geo-location code... (so for miami: brw/mia/wpb)

Recheks in a week (5.11.09 was last tried)

	* This thread:
	http://sfbay.craigslist.org/forums/?ID=29345737
	Title: craigwatch does this - if you're a little handy 
	Message: 
		craigwatch and libcraigscrape are a tightly-coupled, ruby solution for (largely) unix-based systems. 
		<br>
		<br>
		Check it out here: 
		<br>
		<a target="_top" href="http://www.derosetechnologies.com/community/libcraigscrape">http://www.derosetechnologies.com/community/libcraigscrape</a>
	* http://www.craigslistwatch.com/
	* Did this actuallyt post?: http://digg.com/tech_news/Stop_wasting_money_use_Craigslist_Watch

email: 
	http://www.craigdiddy.com/competition.html
	http://www.dostuffright.com/Craigwatch
	http://wareseeker.com/Network-Internet/Craigslist-All-City-Search-Tool-1.2.zip/8036652
	http://www.killerstartups.com/Search/craigslittlebuddy-com-multiple-city-craigslist-search
	
Scripts aggregators:
	  bigwebmaster.com 
	http://www.scripts.com/
	http://www.scriptarchive.com/
	http://www.needscripts.com/
	http://www.scriptsearch.com/
	http://www.sitescripts.com/PHP/
	http://www.scriptsbank.com/
------------------------------------------
# Quickie craigscrape examples/tests:
$: << './lib'
require 'libcraigscrape'

CraigScrape.new('us/fl/miami', 'us/fl/keys').posts_since(Time.now - 3600*48, 'search/sss?query=z06')
CraigScrape.new('us/fl/miami').posts('search/sss?query=z06')
i=0; CraigScrape.new('us/fl/miami', 'us/fl/keys').each_post('rea', 'search/sss?query=rack'){|p| break if i>50; puts p.inspect ;i += 1;}
CraigScrape.new('us/fl/miami', 'us/fl/keys').each_listing('rea', 'search/sss?query=rack'){ |listing| puts listing.inspect }
CraigScrape.new('us/fl/miami', 'us/fl/keys').listings('rea', 'search/sss?query=rack')


-----------------------------------------
# Quickie way to analyze an email:
$: << './lib'
require 'libcraigscrape'

email=<<EOD
email contents here
EOD
r=/regex-here/

email.tr('\n', '').scan( /http\:\/\/[^ \"]+/).reject{|l| !/\.html/.match l}.each{ |l|
  puts "\nURL: %s" % l
  c = CraigScrape::Posting.new l
  puts "  * Label : %s" % r.match(c.label).to_a[0]
  puts "  * Contents: %s" % r.match(c.contents_as_plain).to_a[0]
}
